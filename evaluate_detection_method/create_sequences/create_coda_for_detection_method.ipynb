{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CODA for Sartoris' detection method (KITTI odometry format) (runtime: ~ 6h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pcl\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "#from nuscenes.scripts.export_kitti import KittiConverter\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "from x2poses.nuscenes2kitti import KittiConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set paths\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h4>ToDo:</h4>\n",
    "<ol>\n",
    "    <li> Set \"datasets_root\" to the root of your <b>dataset directory</b>\n",
    "    <li> Set \"coda_root\" to the root of your new <b>CODA directory</b>\n",
    "    <li> Set \"vanishing_data_root\" to your <b>working directory</b>\n",
    "    <li> Select which dataset you want to create\n",
    "    <li> Select which parts of the datasets to create\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_root = f'/disk/ml/datasets/'\n",
    "coda_root = f'/disk/ml/own_datasets/CODA/'\n",
    "vanishing_data_root = f'/disk/vanishing_data/ju878'\n",
    "\n",
    "do_kitti = True\n",
    "do_nuscenes = True\n",
    "do_once = True\n",
    "\n",
    "copy_images = True\n",
    "copy_velodyne = True\n",
    "copy_calib = True\n",
    "copy_poses = True\n",
    "copy_timestamps = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_raw_root = os.path.join(datasets_root, 'KITTI_Raw')\n",
    "kitti_object_calib_root = os.path.join(datasets_root, 'KITTI/object/data/training/calib')\n",
    "nuscenes_root = os.path.join(datasets_root, 'nuScenes')\n",
    "once_root = os.path.join(datasets_root, 'ONCE/data_root/data')\n",
    "\n",
    "corner_case_file = os.path.join(coda_root, 'corner_case.json')\n",
    "kitti_mapping_file = os.path.join(coda_root, 'kitti_mapping.json')\n",
    "nuscenes_indices_file = os.path.join(coda_root, 'nuscenes_indices.json')\n",
    "\n",
    "prepared_poses = os.path.join(vanishing_data_root, 'prepared_poses')\n",
    "nuscenes_poses_folder = os.path.join(prepared_poses, 'nuscenes/poses')\n",
    "once_poses_folder = os.path.join(prepared_poses, 'once/poses')\n",
    "kitti_poses_folder = os.path.join(prepared_poses, 'kitti/poses')\n",
    "\n",
    "new_dataset_root = os.path.join(vanishing_data_root, 'CODA_for_detection_method')\n",
    "sequence_folder = os.path.join(new_dataset_root, 'sequences')\n",
    "poses_folder= os.path.join(new_dataset_root, 'poses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "once_pattern = r'^\\D*(\\d\\D*){6}$'\n",
    "\n",
    "if not os.path.exists(sequence_folder):\n",
    "        os.makedirs(sequence_folder)\n",
    "\n",
    "if not os.path.exists(poses_folder):\n",
    "        os.makedirs(poses_folder)\n",
    "        \n",
    "        \n",
    "with open(corner_case_file, 'r') as f:\n",
    "    corner_case = json.load(f)\n",
    "\n",
    "with open(kitti_mapping_file, 'r') as f:\n",
    "    kitti_mapping = json.load(f)\n",
    "    \n",
    "with open(nuscenes_indices_file, 'r') as f:\n",
    "    nuscenes_indices = json.load(f)\n",
    "\n",
    "images = corner_case['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc_version = f'v1.0-trainval'\n",
    "nusc_sensor_image = f'CAM_FRONT'\n",
    "nusc_sensor_lidar = f'LIDAR_TOP'\n",
    "num_images = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load nuScenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 55.145 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 7.7 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "nusc = NuScenes(version=nusc_version, dataroot=nuscenes_root, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_conv = KittiConverter(poses_folder, nusc_sensor_image, nusc_sensor_lidar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read calibration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_calib(calib_path):\n",
    "    data = {}\n",
    "    with open(calib_path, 'r') as f:\n",
    "        lines = filter(None, (line.rstrip() for line in f))\n",
    "        for line in lines:\n",
    "            if line == ' ':\n",
    "                break\n",
    "            else:\n",
    "                key, value = line.split(':', 1)\n",
    "                # The only non-float values in these files are dates, which\n",
    "                # we don't care about anyway\n",
    "                try:\n",
    "                    data[key] = np.array([float(x) for x in value.split()])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamp to unix ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kitti_timestamp_to_ms(timestamp):\n",
    "    parts = timestamp.split(' ')[1].replace('\\n','').split(':')\n",
    "    h = float(parts[0])\n",
    "    m = float(parts[1])\n",
    "    s = float(parts[2].split('.')[0])\n",
    "    ms = float(parts[2].split('.')[1]) / 1000000\n",
    "    \n",
    "    new_times = (h * 60 * 60 * 1000) + (m * 60 * 1000) + (s * 1000) + ms\n",
    "    \n",
    "    return new_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert CODA into KITTIodometry format for detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in tqdm(images):\n",
    "    id = image['id']\n",
    "    file_name = image['file_name'].split('.')[0]\n",
    "    prefix, name = file_name.split('_')\n",
    "    \n",
    "    id_str = '{:0>4}'.format(id)\n",
    "    sequence_root = os.path.join(sequence_folder, id_str)\n",
    "    \n",
    "    \n",
    "    if prefix == 'kitti' and do_kitti:\n",
    "        file_name_ending = f'{file_name}.png'\n",
    "        calib = read_calib(os.path.join(kitti_object_calib_root, name + '.txt'))\n",
    "        image_2_folder = os.path.join(sequence_root, 'image_2')\n",
    "        velodyne_folder = os.path.join(sequence_root, 'velodyne')\n",
    "        \n",
    "        raw_file_name = kitti_mapping[file_name_ending].replace('\\n','').split(' ')\n",
    "        raw_sequence_root = os.path.join(kitti_raw_root, raw_file_name[0], raw_file_name[1])\n",
    "        raw_poses_folder = os.path.join(kitti_poses_folder, raw_file_name[0], raw_file_name[1])\n",
    "        raw_timestamp_file = os.path.join(raw_sequence_root, 'velodyne_points/timestamps.txt')\n",
    "        \n",
    "        raw_image_number = int(raw_file_name[2])\n",
    "        \n",
    "        if raw_image_number >= num_images:\n",
    "              \n",
    "            if not os.path.exists(sequence_root):\n",
    "                os.makedirs(sequence_root)\n",
    "            \n",
    "            if not os.path.exists(image_2_folder):\n",
    "                os.makedirs(image_2_folder)\n",
    "                \n",
    "            if not os.path.exists(velodyne_folder):\n",
    "                os.makedirs(velodyne_folder)\n",
    "                    \n",
    "            if copy_images or copy_velodyne:\n",
    "                for i in range(raw_image_number - num_images, raw_image_number + num_images + 1):\n",
    "                    \n",
    "                    old_file_number = '{:0>10}'.format(i)\n",
    "                    source_image = os.path.join(raw_sequence_root, 'image_02/data', str(old_file_number) + '.png')\n",
    "                    source_lidar = os.path.join(raw_sequence_root, 'velodyne_points/data', str(old_file_number) + '.bin')\n",
    "\n",
    "                    new_file_number = -raw_image_number + num_images + i\n",
    "                    destination_image = os.path.join(image_2_folder, file_name + '_' + str(new_file_number) + '.png')\n",
    "                    destination_lidar = os.path.join(velodyne_folder, file_name + '_' + str(new_file_number) + '.bin')\n",
    "                    \n",
    "                    shutil.copy(source_image, destination_image)\n",
    "                    shutil.copy(source_lidar, destination_lidar)\n",
    "                    \n",
    "            if copy_calib:\n",
    "                Tr_velo_to_cam = np.vstack((calib['Tr_velo_to_cam'].reshape(3, 4), [0, 0, 0, 1]))\n",
    "                R0_rect = np.eye(4)\n",
    "                R0_rect[0:3, 0:3] = np.reshape(calib['R0_rect'], (3, 3))\n",
    "                Tr = R0_rect.dot(Tr_velo_to_cam)\n",
    "                \n",
    "                kitti_transforms = dict()\n",
    "                kitti_transforms['P0'] = calib['P0'].reshape(3, 4)\n",
    "                kitti_transforms['P1'] = calib['P1'].reshape(3, 4)\n",
    "                kitti_transforms['P2'] = calib['P2'].reshape(3, 4)\n",
    "                kitti_transforms['P3'] = calib['P3'].reshape(3, 4)\n",
    "                kitti_transforms['Tr'] = Tr[0:3][0:4]\n",
    "                calib_path = os.path.join(sequence_root, 'calib.txt')\n",
    "                \n",
    "                with open(calib_path, \"w\") as f:\n",
    "                    for (key, val) in kitti_transforms.items():\n",
    "                        val = val.flatten()\n",
    "                        val_str = '%.12e' % val[0]\n",
    "                        for v in val[1:12]:\n",
    "                            val_str += ' %.12e' % v\n",
    "                        f.write('%s: %s\\n' % (key, val_str))\n",
    "                        \n",
    "            if copy_poses:   \n",
    "                poses = []\n",
    "                \n",
    "                with open(os.path.join(raw_poses_folder, 'poses.txt'), 'r') as f:\n",
    "                    lines = filter(None, (line.rstrip() for line in f))\n",
    "                    for index, line in enumerate(lines):\n",
    "                        if index >= raw_image_number - num_images and index <= raw_image_number + num_images:\n",
    "                            poses.append(line)\n",
    "                            \n",
    "                pose_file = '{:0>4}'.format(id)\n",
    "                with open(os.path.join(poses_folder, pose_file + '.txt'), 'w') as f:\n",
    "                    for pose in poses:\n",
    "                        f.write('%s\\n' % (pose))\n",
    "                with open(os.path.join(sequence_root, 'poses.txt'), 'w') as f:\n",
    "                    for pose in poses:\n",
    "                        f.write('%s\\n' % (pose)) \n",
    "                        \n",
    "            if copy_timestamps:\n",
    "                times = []\n",
    "                first_time = 0\n",
    "                \n",
    "                with open(raw_timestamp_file, 'r') as f:\n",
    "                    lines = filter(None, (line.rstrip() for line in f))\n",
    "                    for index, line in enumerate(lines):\n",
    "                        if index == 0:\n",
    "                            first_time = kitti_timestamp_to_ms(line)\n",
    "                        if index >= raw_image_number - num_images and index <= raw_image_number + num_images:\n",
    "                            time = kitti_timestamp_to_ms(line)\n",
    "                            time_diff = time - first_time\n",
    "                            times.append(time_diff / 1000)\n",
    "                            \n",
    "                times.sort()\n",
    "                with open(os.path.join(sequence_root, 'times.txt'), 'w') as f:\n",
    "                    for time in times:\n",
    "                        f.write('%s\\n' % (time)) \n",
    "                            \n",
    "    elif prefix == 'nuscenes' and do_nuscenes:\n",
    "        sample_tokens = []\n",
    "        sample_names = []\n",
    "        nuscenes_token = nuscenes_indices[image['file_name']]\n",
    "        sample = nusc.get('sample', nuscenes_token)\n",
    "        scene = nusc.get('scene', sample['scene_token'])\n",
    "        scene_name = scene['name']\n",
    "        \n",
    "        prev = sample\n",
    "        next = sample\n",
    "        \n",
    "        sample_tokens.append(sample['token'])\n",
    "        sample_names.append(f'{file_name}_{num_images}')\n",
    "        \n",
    "        counter_prev = 0\n",
    "        counter_next = 0\n",
    "        \n",
    "        while prev['prev'] != '':\n",
    "            counter_prev += 1\n",
    "            prev = nusc.get('sample', prev['prev'])  \n",
    "        while next['next'] != '':\n",
    "            counter_next += 1\n",
    "            next = nusc.get('sample', next['next'])\n",
    "        \n",
    "        prev = sample\n",
    "        next = sample\n",
    "        \n",
    "        if counter_prev >= num_images and counter_next >= num_images:   \n",
    "            \n",
    "            if not os.path.exists(sequence_root):\n",
    "                os.makedirs(sequence_root)\n",
    "            \n",
    "            if copy_images or copy_velodyne or copy_calib or copy_timestamps:\n",
    "                for i in range(1, num_images + 1):\n",
    "                    prev = nusc.get('sample', prev['prev'])\n",
    "                    sample_tokens.append(prev['token'])\n",
    "                    sample_names.append(f'{file_name}_{num_images - i}')\n",
    "                    \n",
    "                    next = nusc.get('sample', next['next'])\n",
    "                    sample_tokens.append(next['token'])\n",
    "                    sample_names.append(f'{file_name}_{num_images + i}')\n",
    "                    \n",
    "                kitti_conv.nuscenes_gt_to_kitti(sample_tokens, sample_names, sequence_root, nusc)\n",
    "            \n",
    "            if copy_poses:\n",
    "                poses = []\n",
    "                np_poses = []\n",
    "\n",
    "                with open(os.path.join(nuscenes_poses_folder, scene_name + '.txt'), 'r') as f:\n",
    "                    lines = filter(None, (line.rstrip() for line in f))\n",
    "                    for index, line in enumerate(lines):\n",
    "                        if index >= counter_prev - num_images and index <= counter_prev + num_images:\n",
    "                            poses.append(line)\n",
    "                            np_poses.append(np.array([float(x) for x in line.split()]))\n",
    "                            \n",
    "                pose_file = '{:0>4}'.format(id)\n",
    "                with open(os.path.join(poses_folder, pose_file + '.txt'), 'w') as f:\n",
    "                    for pose in poses:\n",
    "                        f.write('%s\\n' % (pose)) \n",
    "                with open(os.path.join(sequence_root, 'poses.txt'), 'w') as f:\n",
    "                    for pose in poses:\n",
    "                        f.write('%s\\n' % (pose)) \n",
    "            \n",
    "    elif re.match(once_pattern, prefix) and do_once:\n",
    "        image_2_folder = os.path.join(sequence_root, 'image_2')\n",
    "        velodyne_folder = os.path.join(sequence_root, 'velodyne')\n",
    "        \n",
    "        sequence, file = file_name.split('.')[0].split('_')\n",
    "        once_sequence_root = os.path.join(once_root, sequence)\n",
    "        once_image_root = os.path.join(once_sequence_root, 'cam03')\n",
    "        once_lidar_root = os.path.join(once_sequence_root, 'lidar_roof')\n",
    "        once_json_file = os.path.join(once_sequence_root, sequence + '.json')\n",
    "        \n",
    "        with open(once_json_file, 'r') as f:\n",
    "            once_json = json.load(f)\n",
    "        \n",
    "        calib = once_json['calib']\n",
    "        calib = calib['cam03']\n",
    "        \n",
    "        cam_to_velo = np.array(calib['cam_to_velo'])\n",
    "        velo_to_cam = np.linalg.inv(cam_to_velo)\n",
    "        new_velo_to_cam = np.zeros_like(velo_to_cam)\n",
    "        new_velo_to_cam[:, 1] = velo_to_cam[:, 0]\n",
    "        new_velo_to_cam[:, 0] = -velo_to_cam[:, 1]\n",
    "        new_velo_to_cam[:, 2] = velo_to_cam[:, 2]\n",
    "        \n",
    "        cam_intrinsic = np.array(calib['cam_intrinsic'])\n",
    "        distortion = np.array(calib['distortion'])\n",
    "        \n",
    "        cam_intrinsic_n, roi = cv2.getOptimalNewCameraMatrix(cam_intrinsic, distortion, (1920, 1020), alpha=0.0, newImgSize=(1920, 1020))\n",
    "        cam_intrinsic = np.hstack([cam_intrinsic_n, np.zeros((3, 1), dtype=np.float32)]) \n",
    "        \n",
    "        \n",
    "        frames = once_json['frames']\n",
    "        \n",
    "        kitti_to_once_lidar = Quaternion(axis=(0, 0, 1), angle=np.pi * 3 / 2)\n",
    "        kitti_to_once_lidar_inv = kitti_to_once_lidar.inverse\n",
    "        \n",
    "        velo_to_cam_kitti = np.dot(velo_to_cam, kitti_to_once_lidar.transformation_matrix)\n",
    "        \n",
    "        first_timestamp = frames[0]['frame_id']\n",
    "        frames_len = len(frames)\n",
    "        file_index = 0\n",
    "        for index, frame in enumerate(frames):\n",
    "            if frame['frame_id'] == file:\n",
    "                file_index = index\n",
    "                \n",
    "        \n",
    "        if file_index >= num_images and file_index <= frames_len - num_images - 1:\n",
    "            \n",
    "            if not os.path.exists(sequence_root):\n",
    "                os.makedirs(sequence_root)\n",
    "            if not os.path.exists(image_2_folder):\n",
    "                os.makedirs(image_2_folder)\n",
    "            if not os.path.exists(velodyne_folder):\n",
    "                os.makedirs(velodyne_folder)\n",
    "            \n",
    "            if copy_images or copy_velodyne:    \n",
    "                for index, frame_index in enumerate(range(file_index - num_images , file_index + num_images + 1)):\n",
    "                    \n",
    "                    once_file_name = frames[frame_index]['frame_id']\n",
    "                    source_image = os.path.join(once_image_root, once_file_name + '.jpg')\n",
    "                    source_lidar = os.path.join(once_lidar_root, once_file_name + '.bin')\n",
    "                    \n",
    "                    destination_image = os.path.join(image_2_folder, file_name + '_' + str(index) + '.png')\n",
    "                    destination_lidar = os.path.join(velodyne_folder, file_name + '_' + str(index) + '.bin')\n",
    "                    \n",
    "                    img = cv2.imread(source_image)\n",
    "                    dst = cv2.undistort(img, np.array(calib['cam_intrinsic']), distortion, None, cam_intrinsic_n)\n",
    "                    x, y, w, h = roi\n",
    "                    dst = dst[y:y+h, x:x+w]\n",
    "                    cv2.imwrite(destination_image, dst)\n",
    "                    \n",
    "                    points = np.fromfile(source_lidar, dtype=np.float32).reshape((-1, 4))\n",
    "                    new_points = np.zeros_like(points)\n",
    "                    new_points[:, 1] = points[:, 0]\n",
    "                    new_points[:, 0] = -points[:, 1]\n",
    "                    new_points[:, 2] = points[:, 2]\n",
    "                    with open(destination_lidar, \"w\") as lid_file:\n",
    "                        new_points.tofile(lid_file)                       \n",
    "            \n",
    "            if copy_calib:\n",
    "                \n",
    "                kitti_transforms = dict()\n",
    "                kitti_transforms['P0'] = np.zeros((3, 4))  # Dummy values.\n",
    "                kitti_transforms['P1'] = np.zeros((3, 4))  # Dummy values.\n",
    "                kitti_transforms['P2'] = cam_intrinsic \n",
    "                kitti_transforms['P3'] = np.zeros((3, 4))  # Dummy values.\n",
    "                kitti_transforms['Tr'] = new_velo_to_cam[:3, :] \n",
    "                calib_path = os.path.join(sequence_root, 'calib.txt')\n",
    "                with open(calib_path, \"w\") as calib_file:\n",
    "                    for (key, val) in kitti_transforms.items():\n",
    "                        val = val.flatten()\n",
    "                        val_str = '%.12e' % val[0]\n",
    "                        for v in val[1:]:\n",
    "                            val_str += ' %.12e' % v\n",
    "                        calib_file.write('%s: %s\\n' % (key, val_str))\n",
    "                        \n",
    "            if copy_poses:\n",
    "                poses = []\n",
    "                np_poses = []\n",
    "                \n",
    "                with open(os.path.join(once_poses_folder, sequence + '.txt'), 'r') as f:\n",
    "                    lines = filter(None, (line.rstrip() for line in f))\n",
    "                    for index, line in enumerate(lines):\n",
    "                        if index >= file_index - num_images and index <= file_index + num_images:\n",
    "                            poses.append(line)\n",
    "                            np_poses.append(np.array([float(x) for x in line.split()]))\n",
    "                pose_file = '{:0>4}'.format(id)\n",
    "                with open(os.path.join(poses_folder, pose_file + '.txt'), 'w') as f:\n",
    "                    for index, pose in enumerate(np_poses):\n",
    "                        if index == 0:\n",
    "                            f.write('1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0\\n')\n",
    "                        else:\n",
    "                            pose = pose.flatten()\n",
    "                            pose_str = '' \n",
    "                            for i, p in enumerate(pose):\n",
    "                                if i == 0:\n",
    "                                    pose_str += '%.12e' % (p + (1 - np_poses[0].flatten()[i]))\n",
    "                                elif i == 5 or i == 10:\n",
    "                                    pose_str += ' %.12e' % (p + (1 - np_poses[0].flatten()[i]))\n",
    "                                else:\n",
    "                                    pose_str += ' %.12e' % (p + (0 - np_poses[0].flatten()[i]))\n",
    "                            f.write('%s\\n' % (pose_str))\n",
    "                with open(os.path.join(sequence_root, 'poses.txt'), 'w') as f:\n",
    "                    for pose in poses:\n",
    "                        f.write('%s\\n' % (pose))\n",
    "            \n",
    "            if copy_timestamps:\n",
    "                times = []\n",
    "                for index, frame_index in enumerate(range(file_index - num_images , file_index + num_images + 1)):\n",
    "                    timestamp = frames[frame_index]['frame_id']\n",
    "                    time_diff = float(timestamp) - float(first_timestamp)\n",
    "                    times.append(time_diff / 1000)\n",
    "                            \n",
    "                times.sort()\n",
    "                with open(os.path.join(sequence_root, 'times.txt'), 'w') as f:\n",
    "                    for time in times:\n",
    "                        f.write('%s\\n' % (time)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
