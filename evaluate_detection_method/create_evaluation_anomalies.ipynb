{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create anomalies evaluation (runtime: ~ 2.5h) (Inspired by: https://github.com/daniel-bogdoll/supervised_unsupervised_anomaly/blob/main/anomaly_detection/compare_and_cluster/map_anomalies_on_image.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import json\n",
    "import yaml\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set paths and load config\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>ToDo:</b> Set \"coda_root\" to your <b>working directory</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coda_root = f'/disk/ml/own_datasets/CODA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = os.path.realpath('../../model_contradictions/')\n",
    "supervised_unsupervised_root = os.path.join(model_root, 'supervised_unsupervised_anomaly')\n",
    "config_filename = os.path.join(supervised_unsupervised_root, 'anomaly_detection/config/config_paths.yaml')\n",
    "json_corner_cases = os.path.join(coda_root, 'corner_case.json')\n",
    "\n",
    "config = yaml.load(open(config_filename), Loader=yaml.FullLoader)\n",
    "\n",
    "with open(json_corner_cases, 'r') as f:\n",
    "    data_cornercases = json.load(f)\n",
    "    \n",
    "annotations = data_cornercases['annotations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to create images evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read calib file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_calib_file(filepath, data_dic):    \n",
    "    \"\"\"\n",
    "    Inspired by: https://github.com/utiasSTARS/pykitti/blob/master/pykitti/utils.py\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.rstrip()\n",
    "\n",
    "            if len(line) == 0: continue\n",
    "            key, value = line.split(':', 1)\n",
    "\n",
    "            data_dic[key] = np.array([float(x) for x in value.split()])\n",
    "    return data_dic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create velo_to_cam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_velo_to_cam2(calib):\n",
    "    \"\"\"\n",
    "    Inspired by: https://github.com/darylclimb/cvml_project/blob/master/projections/lidar_camera_projection/utils.py\n",
    "    \"\"\"\n",
    "    P_velo2cam_ref = np.vstack((calib['Tr'].reshape(3, 4), np.array([0., 0., 0., 1.])))  # velo2ref_cam\n",
    "    P_rect2cam2 = calib['P2'].reshape((3, 4))\n",
    "    proj_mat = P_rect2cam2 @ P_velo2cam_ref\n",
    "    \n",
    "    return proj_mat, P_velo2cam_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate points into 2D image space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_to_image(points, proj_mat):\n",
    "    \"\"\"\n",
    "    Inspired by: https://github.com/darylclimb/cvml_project/blob/master/projections/lidar_camera_projection/utils.py\n",
    "    \"\"\"\n",
    "    num_pts = points.shape[1]\n",
    "\n",
    "    points = np.vstack((points, np.ones((1, num_pts))))\n",
    "    points = proj_mat @ points\n",
    "    points[:2, :] /= points[2, :]\n",
    "    \n",
    "    return points[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get colors for each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_and_colors(anomaly_labels, color_dict):\n",
    "    if color_dict:\n",
    "        max_sem_key = 0\n",
    "        for key, data in color_dict.items():\n",
    "            if key + 1 > max_sem_key:\n",
    "                max_sem_key = key + 1\n",
    "        color_lut = np.zeros((max_sem_key + 100, 3), dtype=np.float32)\n",
    "        for key, value in color_dict.items():\n",
    "            color_lut[key] = np.array(value, np.float32)\n",
    "    else:\n",
    "        quit()\n",
    "\n",
    "    sem_label = np.zeros((0, 1), dtype=np.int16)\n",
    "    sem_label_color = np.zeros((0, 3), dtype=np.float32)\n",
    "\n",
    "    sem_label = anomaly_labels\n",
    "    sem_label_color = color_lut[sem_label]\n",
    "    sem_label_color = sem_label_color.reshape((-1, 3))\n",
    "\n",
    "    #check\n",
    "    assert(sem_label.shape[0] == sem_label_color.shape[0])\n",
    "\n",
    "    return sem_label_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create image with projected points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_camerafov(pts_velo, calib, img, img_width, img_height, label_color, dataset):\n",
    "    \"\"\"\n",
    "    Inspired by: https://github.com/darylclimb/cvml_project/blob/master/projections/lidar_camera_projection/utils.py\n",
    "    \"\"\"\n",
    "    # projection matrix (project from velo2cam2)\n",
    "    pts_velo_xyz = pts_velo[:, :3]\n",
    "    proj_velo2cam2, P_velo2cam_ref = project_velo_to_cam2(calib)\n",
    "\n",
    "    # apply projection\n",
    "    pts_2d = project_to_image(pts_velo_xyz.transpose(), proj_velo2cam2)\n",
    "    \n",
    "\n",
    "    inds = np.where((pts_2d[0, :] < img_width) & (pts_2d[0, :] >= 0) &\n",
    "                (pts_2d[1, :] < img_height) & (pts_2d[1, :] >= 0) &\n",
    "                (pts_velo_xyz[:, 0] > 0)\n",
    "                )[0]\n",
    "    \n",
    "    if dataset == 'nuscenes':\n",
    "        inds = np.where((pts_2d[0, :] < img_width) & (pts_2d[0, :] >= 0) &\n",
    "                    (pts_2d[1, :] < img_height) & (pts_2d[1, :] >= 0) &\n",
    "                    (pts_velo_xyz[:, 0] > 1)\n",
    "                    )[0]\n",
    "    elif dataset == 'once':      \n",
    "        inds = np.where((pts_2d[0, :] < img_width) & (pts_2d[0, :] >= 0) &\n",
    "                    (pts_2d[1, :] < img_height) & (pts_2d[1, :] >= 0) &\n",
    "                    (pts_velo_xyz[:, 0] > 0)\n",
    "                    )[0]\n",
    "\n",
    "    # Filter out pixels points\n",
    "    imgfov_pc_pixel = pts_2d[:, inds]   #xy\n",
    "\n",
    "    #Filter semantic color\n",
    "    sem_label_color_velo = label_color[inds, :]\n",
    "    sem_label_color_velo = np.array(sem_label_color_velo).astype(np.int16)\n",
    "    \n",
    "    for i in range(imgfov_pc_pixel.shape[1]):\n",
    "        color_label = np.array(sem_label_color_velo[i, :])\n",
    "        b=int(color_label[0])\n",
    "        g=int(color_label[1])\n",
    "        r=int(color_label[2])\n",
    "        cv2.circle(img, (int(np.round(imgfov_pc_pixel[0, i])),\n",
    "                int(np.round(imgfov_pc_pixel[1, i]))),\n",
    "                2, color=(b,g,r), thickness=-1)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img_to_file(img, path_to_save, seq):\n",
    "    if not os.path.exists(os.path.join(path_to_save, seq)):\n",
    "        os.makedirs(os.path.join(path_to_save, seq))\n",
    "    save_path = os.path.join(path_to_save, seq, seq + '.png')\n",
    "    cv2.imwrite(save_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save counts, points, and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_counts_points_labels(path_save, anno, points, labels, counts):\n",
    "    if not os.path.exists(os.path.join(path_save, anno)):\n",
    "        os.makedirs(os.path.join(path_save, anno))\n",
    "    with open(path_save + '/counts.txt', 'a') as f:\n",
    "        counts_string = ','.join(map(str, counts))\n",
    "        f.write(counts_string + '\\n')\n",
    "    points.astype('float32').tofile(os.path.join(path_save, anno, anno + '_points.bin'))\n",
    "    labels.astype('float32').tofile(os.path.join(path_save, anno, anno + '_labels.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine ground truth and detection method labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_gt_and_detection_method_labels(gt_labels, dm_labels):\n",
    "    points = []\n",
    "    labels = []\n",
    "    used_points = [False] * len(dm_labels)\n",
    "    for o_point in gt_labels:\n",
    "        for index, n_point in enumerate(dm_labels):\n",
    "            if o_point[0] + 0.001 >= n_point[0] and o_point[0] - 0.001 <= n_point[0] and o_point[1] + 0.001 >= n_point[1] and o_point[1] - 0.001 <= n_point[1] and o_point[2] + 0.001 >= n_point[2] and o_point[2] - 0.001 <= n_point[2]:\n",
    "                points.append(o_point[:3])\n",
    "                used_points[index] = True\n",
    "                if o_point[4] == -1:\n",
    "                    if n_point[3] == 1:\n",
    "                        labels.append(-11)\n",
    "                    elif n_point[3] == 2:\n",
    "                        labels.append(-12)\n",
    "                    elif n_point[3] == 3:\n",
    "                        labels.append(-13)\n",
    "                    elif n_point[3] == 4:\n",
    "                        labels.append(-14)\n",
    "                elif o_point[4] == 1:\n",
    "                    if n_point[3] == 1:\n",
    "                        labels.append(11)\n",
    "                    elif n_point[3] == 2:\n",
    "                        labels.append(12)\n",
    "                    elif n_point[3] == 3:\n",
    "                        labels.append(13)\n",
    "                    elif n_point[3] == 4:\n",
    "                        labels.append(14)\n",
    "                break\n",
    "        else:\n",
    "            points.append(o_point[:3])\n",
    "            if o_point[4] == -1:\n",
    "                labels.append(-10)\n",
    "            elif o_point[4] == 1:\n",
    "                labels.append(10)    \n",
    "    \n",
    "    points = np.array(points).reshape((-1, 3)) \n",
    "    labels = np.array(labels).reshape((-1, 1))\n",
    "\n",
    "    return points, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the counts for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_counts(labels, gt_labels, dm_labels):\n",
    "    c_11 = np.count_nonzero(labels == -11)\n",
    "    c_12 = np.count_nonzero(labels == -12)\n",
    "    c_13 = np.count_nonzero(labels == -13)\n",
    "    c_14 = np.count_nonzero(labels == -14)\n",
    "    c11 = np.count_nonzero(labels == 11)\n",
    "    c12 = np.count_nonzero(labels == 12)\n",
    "    c13 = np.count_nonzero(labels == 13)\n",
    "    c14 = np.count_nonzero(labels == 14)\n",
    "    c_10 = np.count_nonzero(labels == -10)\n",
    "    c10 = np.count_nonzero(labels == 10)\n",
    "    c1 = 0\n",
    "    c2 = 0   \n",
    "    c3 = 0  \n",
    "    c4 = 0\n",
    "    tp = c13 + c14\n",
    "    fp = c_13 + c_14 + c3 + c4\n",
    "    fn = c11 + c12 + c10\n",
    "    tn = c_11 + c_12 + c_10 + c1 + c2\n",
    "    total = labels.shape[0]\n",
    "    gt_total = gt_labels.shape[0]\n",
    "    dm_label_total = dm_labels.shape[0]\n",
    "    \n",
    "    return c_11, c_12, c_13, c_14, c11, c12, c13, c14, c_10, c10, c1, c2, c3, c4, tp, fp, fn, tn, total, gt_total, dm_label_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall combination of all functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluation_images(path_velo, path_labels, path_img, path_gt_label, path_calibrations, path_save, anno, frame_img, dataset):\n",
    "    #open point cloud\n",
    "    pc_velo_camerafov = np.fromfile(path_velo, dtype=np.float32).reshape((-1,3))\n",
    "    anomaly_labels = np.fromfile(path_labels, dtype=np.int16).reshape((-1))\n",
    "    zero_column = np.zeros((1, pc_velo_camerafov.shape[0])) \n",
    "    dm_labels = np.insert(pc_velo_camerafov, 3, anomaly_labels, axis=1)   \n",
    "    dm_labels = np.insert(dm_labels, 4, zero_column, axis=1)\n",
    "    \n",
    "    gt_labels = np.fromfile(path_gt_label, dtype=np.float32).reshape((-1,4))\n",
    "    zero_column = np.zeros((1, gt_labels.shape[0]))    \n",
    "    gt_labels = np.insert(gt_labels, 3, zero_column, axis=1)\n",
    "    \n",
    "    points, labels = combine_gt_and_detection_method_labels(gt_labels, dm_labels)\n",
    "    \n",
    "    counts = create_counts(labels, gt_labels, dm_labels)\n",
    "    \n",
    "    save_counts_points_labels(path_save, anno, points, labels, counts)\n",
    "        \n",
    "    if points.shape[0] == 0:\n",
    "        return\n",
    "    \n",
    "    color_dict = {-1:[0,0,0], 13:[34,139,34], 14:[34,139,34], -13:[178,34,34], -14:[178,34,34], 3:[178,34,34], 4:[178,34,34], 11:[225,225,0], 12:[225,225,0], 10:[225,225,0], -11:[65,105,225], -12:[65,105,225], -10:[65,105,225], 1:[65,105,225], 2:[65,105,225]}\n",
    "    sem_label_color = get_labels_and_colors(labels, color_dict)\n",
    "    \n",
    "    rgb = cv2.cvtColor(cv2.imread(os.path.join(path_img)), cv2.COLOR_BGR2RGB)\n",
    "    img_height, img_width, img_channel = rgb.shape\n",
    "\n",
    "    calib_dic = {}\n",
    "    calib = read_calib_file(path_calibrations, calib_dic)\n",
    "\n",
    "    img = get_point_camerafov(points, calib, rgb, img_width, img_height, sem_label_color, dataset)\n",
    "    \n",
    "    if points.shape[0] != 0:\n",
    "        save_img_to_file(img, path_save, anno)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function to set paths for the individual anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(anno):\n",
    "    seq = '{0:04d}'.format(int(anno['image_id']))\n",
    "    anno = '{0:04d}'.format(int(anno['id']))\n",
    "    \n",
    "    path_dataset = config['path_dataset']\n",
    "    path_inference = config['path_inference']\n",
    "    path_anomalies_sup_self = os.path.join(path_inference, 'anomalies_sup_self')\n",
    "    path_original_labels = os.path.join(path_inference, 'original_labels_annotation')\n",
    "    path_groundtruth_eval = os.path.join(path_inference, 'groundtruth_eval_all_annotation')\n",
    "\n",
    "    if not os.path.exists(os.path.join(path_anomalies_sup_self, seq, 'anomaly_labels')):\n",
    "        if not os.path.exists(os.path.join(path_groundtruth_eval, anno)):\n",
    "            os.makedirs(os.path.join(path_groundtruth_eval, anno))\n",
    "        with open(path_groundtruth_eval + '/counts.txt', 'a') as f:\n",
    "            f.write('%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\\n' % (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\n",
    "        return\n",
    "\n",
    "    frames = os.listdir(os.path.join(path_anomalies_sup_self, seq, 'anomaly_labels'))\n",
    "    frames = sorted(frames, key=lambda x: int(re.findall(r'\\d+', x)[-1]))\n",
    "    \n",
    "    once = r'^\\d{6}_\\d{13}_\\d{1,2}\\.bin$'\n",
    "    \n",
    "    \n",
    "    for frame in range(len(frames)):\n",
    "        frame_label = frames[frame]\n",
    "        if int(frame_label.split('.')[0].split('_')[2]) != 8:\n",
    "            continue\n",
    "        dataset = ''\n",
    "        if re.match(once, frame_label):\n",
    "            dataset = 'once'\n",
    "        elif 'kitti' in frame_label:\n",
    "            dataset = 'kitti'\n",
    "        elif 'nuscenes' in frame_label:\n",
    "            dataset = 'nuscenes'\n",
    "        frame_image = frames[frame].split('.')[0] +'.png'\n",
    "        \n",
    "        path_calib_frame = os.path.join(path_dataset, seq, 'calib.txt')\n",
    "        path_pc_velo_camerafov_frame = os.path.join(path_anomalies_sup_self, seq, 'pc_velo_camerafov', frame_label)\n",
    "        path_anomaly_labels_frame = os.path.join(path_anomalies_sup_self, seq, 'anomaly_labels', frame_label)\n",
    "        path_image_frame = os.path.join(path_dataset, seq, 'image_2', frame_image)\n",
    "        path_original_label_frame = os.path.join(path_original_labels, anno + '.bin')\n",
    "\n",
    "        create_evaluation_images(path_pc_velo_camerafov_frame, path_anomaly_labels_frame, path_image_frame, path_original_label_frame, path_calib_frame, path_groundtruth_eval, anno, frame_image, dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call main function for all anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for anno in tqdm(annotations):\n",
    "        main(anno)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
