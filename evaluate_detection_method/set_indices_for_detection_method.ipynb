{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set indices for Sartoris' detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set indice according to the dataset you want to run\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>ToDo:</b> \n",
    "    <li> 0: load all indices    \n",
    "    <li> 1: load once indices   \n",
    "    <li> 2: load kitti indices \n",
    "    <li> 3: load nuscenes indices\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set paths\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>ToDo:</b> Set \"vanishing_data_root\" to your <b>working directory</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanishing_data_root = f'/disk/vanishing_data/ju878'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = os.path.realpath('../../model_contradictions/')\n",
    "supervised_unsupervised_root = os.path.join(model_root, 'supervised_unsupervised_anomaly')\n",
    "indices_root = os.path.join(model_root, 'create_coda', 'indices')\n",
    "\n",
    "pretrained_models = os.path.join(vanishing_data_root, 'pretrained_models')\n",
    "inference_root = os.path.join(vanishing_data_root, 'log_finn')\n",
    "dataset_root = os.path.join(vanishing_data_root, 'CODA_for_Finn_sequences')\n",
    "sequences_root = os.path.join(dataset_root, 'sequences')\n",
    "preprocessed_root = os.path.join(dataset_root, 'preprocessed')\n",
    "poses_root = os.path.join(dataset_root, 'poses')\n",
    "\n",
    "split = 'valid'\n",
    "\n",
    "semantic_config_file = os.path.join(pretrained_models, 'pretrained_SalsaNext_semantic/kitti_odometry_data_cfg.yaml')\n",
    "mos_config_file = os.path.join(pretrained_models, 'pretrained_SalsaNext_mos/kitti_odometry_data_cfg_mos.yaml')\n",
    "mos_datapreparing_file = os.path.join(supervised_unsupervised_root, 'sup_mos/LiDAR-MOS/config/data_preparing.yaml')\n",
    "combine_mos_config_file = os.path.join(supervised_unsupervised_root, 'sup_mos/LiDAR-MOS/config/combine_mos_semantics.yaml')\n",
    "mos_post_processing_file = os.path.join(supervised_unsupervised_root, 'sup_mos/LiDAR-MOS/config/post-processing.yaml')  \n",
    "flowstep_config_file = os.path.join(supervised_unsupervised_root, 'self_scene_flow/flowstep3d/configs/test/flowstep3d_self_KITTI_odometry.yaml')\n",
    "odometry_config_file = os.path.join(supervised_unsupervised_root, 'self_odometry/DeLORA/config/config_datasets.yaml')\n",
    "anomaly_detection_config_file = os.path.join(supervised_unsupervised_root, 'anomaly_detection/config/config_paths.yaml')\n",
    "anomaly_detection_combine_file = os.path.join(supervised_unsupervised_root, 'anomaly_detection/config/combine_mos_semantics.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load indices and set indices and paths to configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if indice_id == 0:\n",
    "    indices = yaml.safe_load(open(os.path.join(indices_root, 'indices_all.yaml'), 'r'))\n",
    "elif indice_id == 1:\n",
    "    indices = yaml.safe_load(open(os.path.join(indices_root, 'indices_once.yaml'), 'r'))\n",
    "elif indice_id == 2:\n",
    "    indices = yaml.safe_load(open(os.path.join(indices_root, 'indices_kitti.yaml'), 'r'))\n",
    "elif indice_id == 3:\n",
    "    indices = yaml.safe_load(open(os.path.join(indices_root, 'indices_nuscenes.yaml'), 'r'))\n",
    "else:\n",
    "    sys.exit('No valid indice_id! Must be in range 0-3!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set indices and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic_config_file\n",
    "config = yaml.safe_load(open(semantic_config_file, 'r'))\n",
    "config['split']['valid'] = indices['sequences']\n",
    "with open(semantic_config_file, 'w') as f:\n",
    "    f.write(yaml.dump(config))\n",
    "    \n",
    "#mos_datapreparing_file\n",
    "config = yaml.safe_load(open(mos_datapreparing_file, 'r'))\n",
    "config['sequences'] = indices['sequences']\n",
    "config['scan_folder'] = sequences_root\n",
    "with open(mos_datapreparing_file, 'w') as f:\n",
    "    f.write(yaml.dump(config))\n",
    "\n",
    "#mos_config_file\n",
    "config = yaml.safe_load(open(mos_config_file, 'r'))\n",
    "config['split']['valid'] = indices['sequences']\n",
    "with open(mos_config_file, 'w') as f:\n",
    "    f.write(yaml.dump(config))\n",
    "\n",
    "#combine_mos_config_file\n",
    "config = yaml.safe_load(open(combine_mos_config_file, 'r'))\n",
    "config['split']['valid'] = indices['sequences']\n",
    "with open(combine_mos_config_file, 'w') as f:\n",
    "    f.write(yaml.dump(config))\n",
    "\n",
    "#mos_post_processing_file\n",
    "config = yaml.safe_load(open(mos_datapreparing_file, 'r'))\n",
    "config['scan_root'] = sequences_root\n",
    "config['inference_root'] = inference_root\n",
    "config['split'] = split\n",
    "with open(mos_datapreparing_file, 'w') as f:\n",
    "    f.write(yaml.dump(config))\n",
    "\n",
    "#flowstep_config_file\n",
    "config = yaml.safe_load(open(flowstep_config_file, 'r'))\n",
    "config['exp_params']['data']['sequence'] = indices['sequences']\n",
    "config['exp_params']['data']['test_data_root'] = sequences_root\n",
    "config['exp_params']['data']['save_path'] = inference_root\n",
    "with open(flowstep_config_file, 'w') as f:\n",
    "    f.write(yaml.dump(config))\n",
    "\n",
    "#odometry_config_file\n",
    "config = yaml.safe_load(open(odometry_config_file, 'r'))\n",
    "config['kitti']['testing_identifiers'] = indices['sequences']\n",
    "config['kitti']['preprocessed_path'] = preprocessed_root\n",
    "config['kitti']['pose_data_path'] = poses_root\n",
    "config['kitti']['data_path'] = sequences_root\n",
    "with open(odometry_config_file, 'w') as f:\n",
    "    f.write(yaml.dump(config))\n",
    "\n",
    "#anomaly_detection_config_file\n",
    "config = yaml.safe_load(open(anomaly_detection_config_file, 'r'))\n",
    "config['sequences'] = indices['sequences']\n",
    "config['path_dataset'] = sequences_root\n",
    "config['path_inference'] = inference_root\n",
    "with open(anomaly_detection_config_file, 'w') as f:\n",
    "    f.write(yaml.dump(config))\n",
    "\n",
    "#anomaly_detection_combine_file\n",
    "config = yaml.safe_load(open(anomaly_detection_combine_file, 'r'))\n",
    "config['split']['valid'] = indices['sequences']\n",
    "with open(anomaly_detection_combine_file, 'w') as f:\n",
    "    f.write(yaml.dump(config))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
