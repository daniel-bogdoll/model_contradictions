{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.scripts.export_kitti import KittiConverter\n",
    "from nuscenes.utils.data_classes import LidarPointCloud\n",
    "from pyquaternion import Quaternion\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pcl\n",
    "import cv2\n",
    "\n",
    "from pykitti.raw import raw\n",
    "from pykitti import utils\n",
    "from nuscenes2kitti import nuscenes2kitti as nusc2kitti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_root = f'/disk/ml/datasets/'\n",
    "kitti_raw_root = f'{datasets_root}KITTI_Raw/'\n",
    "kitti_object_calib_root = f'{datasets_root}KITTI/object/data/training/calib/'\n",
    "nuscenes_root = f'{datasets_root}nuScenes/'\n",
    "once_root = f'{datasets_root}ONCE/data_root/data/'\n",
    "coda_root = f'/disk/ml/own_datasets/CODA/'\n",
    "\n",
    "corner_case_file = f'{coda_root}corner_case.json'\n",
    "kitti_mapping_file = f'{coda_root}kitti_mapping.json'\n",
    "nuscenes_indices_file = f'{coda_root}nuscenes_indices.json'\n",
    "nuscenes_poses_folder = f'/disk/vanishing_data/ju878/nusc_kitti_test/train/oxts/poses/'\n",
    "once_poses_folder = f'/disk/vanishing_data/ju878/once_kitti_test/poses/'\n",
    "\n",
    "dst_dir = f'/disk/vanishing_data/ju878/CODA_for_Finn_sequences/'\n",
    "sequence_folder = f'{dst_dir}sequences/'\n",
    "poses_folder= f'{dst_dir}poses/'\n",
    "\n",
    "pattern = r'^\\D*(\\d\\D*){6}$'\n",
    "\n",
    "if not os.path.exists(sequence_folder):\n",
    "        os.makedirs(sequence_folder)\n",
    "\n",
    "if not os.path.exists(poses_folder):\n",
    "        os.makedirs(poses_folder)\n",
    "        \n",
    "        \n",
    "with open(corner_case_file, 'r') as f:\n",
    "    corner_case = json.load(f)\n",
    "\n",
    "with open(kitti_mapping_file, 'r') as f:\n",
    "    kitti_mapping = json.load(f)\n",
    "    \n",
    "with open(nuscenes_indices_file, 'r') as f:\n",
    "    nuscenes_indices = json.load(f)\n",
    "\n",
    "\n",
    "images = corner_case['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 1100\n",
    "nusc_version = f'v1.0-trainval'\n",
    "nusc_sensor_image = f'CAM_FRONT'\n",
    "nusc_sensor_lidar = f'LIDAR_TOP'\n",
    "num_images = 8\n",
    "\n",
    "do_kitti = False\n",
    "do_nuscenes = False\n",
    "do_once = True\n",
    "\n",
    "copy_images = True\n",
    "copy_velodyne = False\n",
    "copy_calib = False\n",
    "copy_poses = False\n",
    "copy_timestamps = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 60.348 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 8.5 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "nusc = NuScenes(version=nusc_version, dataroot=nuscenes_root, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_conv = nusc2kitti.KittiConverter(poses_folder, nusc_sensor_image, nusc_sensor_lidar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_calib(calib_path):\n",
    "    data = {}\n",
    "    with open(calib_path, 'r') as f:\n",
    "        lines = filter(None, (line.rstrip() for line in f))\n",
    "        for line in lines:\n",
    "            if line == ' ':\n",
    "                break\n",
    "            else:\n",
    "                key, value = line.split(':', 1)\n",
    "                # The only non-float values in these files are dates, which\n",
    "                # we don't care about anyway\n",
    "                try:\n",
    "                    data[key] = np.array([float(x) for x in value.split()])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kitti_timestamp_to_ms(timestamp):\n",
    "    parts = timestamp.split(' ')[1].replace('\\n','').split(':')\n",
    "    h = float(parts[0])\n",
    "    m = float(parts[1])\n",
    "    s = float(parts[2].split('.')[0])\n",
    "    ms = float(parts[2].split('.')[1]) / 1000000\n",
    "    \n",
    "    new_times = (h * 60 * 60 * 1000) + (m * 60 * 1000) + (s * 1000) + ms\n",
    "    \n",
    "    return new_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "amount = 0\n",
    "numbers = ''\n",
    "numbers_vert = []\n",
    "for image in tqdm(images):\n",
    "    if image['id'] <= image_id:\n",
    "        #image_id = image['id'] - 1\n",
    "        #print(image['id'])\n",
    "        id = image['id']\n",
    "        file_name = image['file_name'].split('.')[0]\n",
    "        prefix, name = file_name.split('_')\n",
    "        \n",
    "        id_str = '{:0>4}'.format(id)\n",
    "        sequence_root = f'{sequence_folder}{id_str}/'\n",
    "        \n",
    "        \n",
    "        if prefix == 'kitti' and do_kitti:\n",
    "            file_name_ending = f'{file_name}.png'\n",
    "            calib = read_calib(f'{kitti_object_calib_root}{name}.txt')\n",
    "            image_2_folder = f'{sequence_root}image_2/'\n",
    "            velodyne_folder = f'{sequence_root}velodyne/'\n",
    "            \n",
    "            raw_file_name = kitti_mapping[file_name_ending].replace('\\n','').split(' ')\n",
    "            raw_sequence_root = f'{kitti_raw_root}{raw_file_name[0]}/{raw_file_name[1]}/'\n",
    "            raw_timestamp_file = f'{raw_sequence_root}velodyne_points/timestamps.txt'\n",
    "            \n",
    "            raw_image_number = int(raw_file_name[2])\n",
    "            \n",
    "            if raw_image_number >= num_images:\n",
    "                  \n",
    "                if not os.path.exists(sequence_root):\n",
    "                    os.makedirs(sequence_root)\n",
    "                \n",
    "                if not os.path.exists(image_2_folder):\n",
    "                    os.makedirs(image_2_folder)\n",
    "\n",
    "                if not os.path.exists(velodyne_folder):\n",
    "                    os.makedirs(velodyne_folder)\n",
    "                    \n",
    "                if copy_images or copy_velodyne:\n",
    "                    for i in range(raw_image_number - num_images, raw_image_number + num_images + 1):\n",
    "\n",
    "                        old_file_number = '{:0>10}'.format(i)\n",
    "                        source_image = f'{raw_sequence_root}image_02/data/{old_file_number}.png'\n",
    "                        source_lidar = f'{raw_sequence_root}velodyne_points/data/{old_file_number}.bin'\n",
    "\n",
    "                        new_file_number = -raw_image_number + num_images + i\n",
    "                        destination_image = f'{image_2_folder}{file_name}_{new_file_number}.png'\n",
    "                        destination_lidar = f'{velodyne_folder}{file_name}_{new_file_number}.bin'\n",
    "\n",
    "                        shutil.copy(source_image, destination_image)\n",
    "                        shutil.copy(source_lidar, destination_lidar)\n",
    "                        \n",
    "                if copy_calib:\n",
    "                    Tr_velo_to_cam = np.vstack((calib['Tr_velo_to_cam'].reshape(3, 4), [0, 0, 0, 1]))\n",
    "                    R0_rect = np.eye(4)\n",
    "                    R0_rect[0:3, 0:3] = np.reshape(calib['R0_rect'], (3, 3))\n",
    "                    Tr = R0_rect.dot(Tr_velo_to_cam)\n",
    "                    \n",
    "                    kitti_transforms = dict()\n",
    "                    kitti_transforms['P0'] = calib['P0'].reshape(3, 4)\n",
    "                    kitti_transforms['P1'] = calib['P1'].reshape(3, 4)\n",
    "                    kitti_transforms['P2'] = calib['P2'].reshape(3, 4)\n",
    "                    kitti_transforms['P3'] = calib['P3'].reshape(3, 4)\n",
    "                    #kitti_transforms['R0_rect'] = r0_rect.rotation_matrix  # Cameras are already rectified.\n",
    "                    kitti_transforms['Tr'] = Tr[0:3][0:4]\n",
    "                    #kitti_transforms['Tr_imu_to_velo'] = imu_to_velo_kitti\n",
    "                    calib_path = os.path.join(sequence_root, 'calib.txt')\n",
    "                    \n",
    "                    with open(calib_path, \"w\") as f:\n",
    "                        for (key, val) in kitti_transforms.items():\n",
    "                            val = val.flatten()\n",
    "                            val_str = '%.12e' % val[0]\n",
    "                            for v in val[1:12]:\n",
    "                                val_str += ' %.12e' % v\n",
    "                            f.write('%s: %s\\n' % (key, val_str))\n",
    "                            \n",
    "                if copy_poses:   \n",
    "                    poses = []\n",
    "\n",
    "                    with open(f'{raw_sequence_root}/poses.txt', 'r') as f:\n",
    "                        lines = filter(None, (line.rstrip() for line in f))\n",
    "                        for index, line in enumerate(lines):\n",
    "                            if index >= raw_image_number - num_images and index <= raw_image_number + num_images:\n",
    "                                poses.append(line)\n",
    "\n",
    "                    pose_file = '{:0>4}'.format(id)\n",
    "                    with open(f'{poses_folder}{pose_file}.txt', 'w') as f:\n",
    "                        for pose in poses:\n",
    "                            f.write('%s\\n' % (pose))\n",
    "                    with open(f'{sequence_root}poses.txt', 'w') as f:\n",
    "                        for pose in poses:\n",
    "                            f.write('%s\\n' % (pose)) \n",
    "                            \n",
    "                if copy_timestamps:\n",
    "                    times = []\n",
    "                    first_time = 0\n",
    "\n",
    "                    with open(f'{raw_timestamp_file}', 'r') as f:\n",
    "                        lines = filter(None, (line.rstrip() for line in f))\n",
    "                        for index, line in enumerate(lines):\n",
    "                            if index == 0:\n",
    "                                first_time = kitti_timestamp_to_ms(line)\n",
    "                            if index >= raw_image_number - num_images and index <= raw_image_number + num_images:\n",
    "                                time = kitti_timestamp_to_ms(line)\n",
    "                                time_diff = time - first_time\n",
    "                                times.append(time_diff / 1000)\n",
    "                                \n",
    "                    times.sort()\n",
    "                    with open(f'{sequence_root}times.txt', 'w') as f:\n",
    "                        for time in times:\n",
    "                            f.write('%s\\n' % (time)) \n",
    "                \n",
    "                amount=amount \n",
    "                numbers = numbers + f'{id},'\n",
    "                numbers_vert.append(f'    - {id}')\n",
    "            else:\n",
    "                if os.path.exists(sequence_root):\n",
    "                    os.rmdir(sequence_root)\n",
    "                #print(id)\n",
    "                amount += 1\n",
    "                \n",
    "                \n",
    "                    \n",
    "        elif prefix == 'nuscenes' and do_nuscenes:\n",
    "            sample_tokens = []\n",
    "            sample_names = []\n",
    "            nuscenes_token = nuscenes_indices[image['file_name']]\n",
    "            sample = nusc.get('sample', nuscenes_token)\n",
    "            scene = nusc.get('scene', sample['scene_token'])\n",
    "            scene_name = scene['name']\n",
    "            \n",
    "            prev = sample\n",
    "            next = sample\n",
    "            \n",
    "            sample_tokens.append(sample['token'])\n",
    "            sample_names.append(f'{file_name}_{num_images}')\n",
    "            \n",
    "            counter_prev = 0\n",
    "            counter_next = 0\n",
    "            \n",
    "            while prev['prev'] != '':\n",
    "                counter_prev += 1\n",
    "                prev = nusc.get('sample', prev['prev'])  \n",
    "            while next['next'] != '':\n",
    "                counter_next += 1\n",
    "                next = nusc.get('sample', next['next'])\n",
    "            \n",
    "            prev = sample\n",
    "            next = sample\n",
    "            \n",
    "            if counter_prev >= num_images and counter_next >= num_images:   \n",
    "                \n",
    "                if not os.path.exists(sequence_root):\n",
    "                    os.makedirs(sequence_root)\n",
    "                \n",
    "                if copy_images or copy_velodyne or copy_calib or copy_timestamps:\n",
    "                    for i in range(1, num_images + 1):\n",
    "                        prev = nusc.get('sample', prev['prev'])\n",
    "                        sample_tokens.append(prev['token'])\n",
    "                        sample_names.append(f'{file_name}_{num_images - i}')\n",
    "\n",
    "                        next = nusc.get('sample', next['next'])\n",
    "                        sample_tokens.append(next['token'])\n",
    "                        sample_names.append(f'{file_name}_{num_images + i}')\n",
    "\n",
    "                    kitti_conv.nuscenes_gt_to_kitti(sample_tokens, sample_names, sequence_root, nusc)\n",
    "                \n",
    "                if copy_poses:\n",
    "                    poses = []\n",
    "                    np_poses = []\n",
    "\n",
    "                    with open(f'{nuscenes_poses_folder}{scene_name}.txt', 'r') as f:\n",
    "                        lines = filter(None, (line.rstrip() for line in f))\n",
    "                        for index, line in enumerate(lines):\n",
    "                            if index >= counter_prev - num_images and index <= counter_prev + num_images:\n",
    "                                poses.append(line)\n",
    "                                np_poses.append(np.array([float(x) for x in line.split()]))\n",
    "                                \n",
    "                    pose_file = '{:0>4}'.format(id)\n",
    "                    with open(f'{poses_folder}{pose_file}.txt', 'w') as f:\n",
    "                        for pose in poses:\n",
    "                            f.write('%s\\n' % (pose)) \n",
    "                    with open(f'{sequence_root}poses.txt', 'w') as f:\n",
    "                        for pose in poses:\n",
    "                            f.write('%s\\n' % (pose)) \n",
    "                            \n",
    "                                \n",
    "                amount = amount\n",
    "                numbers = numbers + f'{id},'\n",
    "                numbers_vert.append(f'    - {id}')\n",
    "            else:\n",
    "                if os.path.exists(sequence_root):\n",
    "                    os.rmdir(sequence_root)\n",
    "                #print(id)\n",
    "                amount += 1\n",
    "                \n",
    "        elif re.match(pattern, prefix) and do_once:\n",
    "            image_2_folder = f'{sequence_root}image_2/'\n",
    "            velodyne_folder = f'{sequence_root}velodyne/'\n",
    "            \n",
    "            sequence, file = file_name.split('.')[0].split('_')\n",
    "            once_sequence_root = f'{once_root}{sequence}/'\n",
    "            once_image_root = f'{once_sequence_root}cam03/'\n",
    "            once_lidar_root = f'{once_sequence_root}lidar_roof/'\n",
    "            once_json_file = f'{once_sequence_root}{sequence}.json'\n",
    "            \n",
    "            with open(once_json_file, 'r') as f:\n",
    "                once_json = json.load(f)\n",
    "            \n",
    "            calib = once_json['calib']\n",
    "            calib = calib['cam03']\n",
    "            \n",
    "            cam_to_velo = np.array(calib['cam_to_velo'])\n",
    "            velo_to_cam = np.linalg.inv(cam_to_velo)\n",
    "            new_velo_to_cam = np.zeros_like(velo_to_cam)\n",
    "            new_velo_to_cam[:, 1] = velo_to_cam[:, 0]\n",
    "            new_velo_to_cam[:, 0] = -velo_to_cam[:, 1]\n",
    "            new_velo_to_cam[:, 2] = velo_to_cam[:, 2]\n",
    "            \n",
    "            cam_intrinsic = np.array(calib['cam_intrinsic'])\n",
    "            distortion = np.array(calib['distortion'])\n",
    "            \n",
    "            #new_cam_intrinsic = np.zeros_like(cam_intrinsic)\n",
    "            #new_cam_intrinsic[1, :] = cam_intrinsic[0, :]\n",
    "            #new_cam_intrinsic[0, :] = -cam_intrinsic[1, :]\n",
    "            #new_cam_intrinsic[2, :] = cam_intrinsic[2, :]\n",
    "            #new_cam_intrinsic_n, _ = cv2.getOptimalNewCameraMatrix(new_cam_intrinsic, distortion, (1920, 1020), alpha=0.0, newImgSize=(1920, 1020))\n",
    "            #new_cam_intrinsic = np.hstack([new_cam_intrinsic_n, np.zeros((3, 1), dtype=np.float32)])\n",
    "            \n",
    "            cam_intrinsic_n, roi = cv2.getOptimalNewCameraMatrix(cam_intrinsic, distortion, (1920, 1020), alpha=0.0, newImgSize=(1920, 1020))\n",
    "            cam_intrinsic = np.hstack([cam_intrinsic_n, np.zeros((3, 1), dtype=np.float32)]) #cam_intrinsic_n\n",
    "            \n",
    "            \n",
    "            frames = once_json['frames']\n",
    "            \n",
    "            kitti_to_once_lidar = Quaternion(axis=(0, 0, 1), angle=np.pi * 3 / 2)\n",
    "            kitti_to_once_lidar_inv = kitti_to_once_lidar.inverse\n",
    "            \n",
    "            velo_to_cam_kitti = np.dot(velo_to_cam, kitti_to_once_lidar.transformation_matrix)\n",
    "            \n",
    "            first_timestamp = frames[0]['frame_id']\n",
    "            frames_len = len(frames)\n",
    "            file_index = 0\n",
    "            for index, frame in enumerate(frames):\n",
    "                if frame['frame_id'] == file:\n",
    "                    file_index = index\n",
    "                    \n",
    "            \n",
    "            if file_index >= num_images and file_index <= frames_len - num_images - 1:\n",
    "                \n",
    "                if not os.path.exists(sequence_root):\n",
    "                    os.makedirs(sequence_root)\n",
    "                if not os.path.exists(image_2_folder):\n",
    "                    os.makedirs(image_2_folder)\n",
    "                if not os.path.exists(velodyne_folder):\n",
    "                    os.makedirs(velodyne_folder)\n",
    "                \n",
    "                if copy_images or copy_velodyne:    \n",
    "                    for index, frame_index in enumerate(range(file_index - num_images , file_index + num_images + 1)):\n",
    "                        \n",
    "                        once_file_name = frames[frame_index]['frame_id']\n",
    "                        source_image = f'{once_image_root}{once_file_name}.jpg'\n",
    "                        source_lidar = f'{once_lidar_root}{once_file_name}.bin'\n",
    "                        \n",
    "                        destination_image = f'{image_2_folder}{file_name}_{index}.png'\n",
    "                        destination_lidar = f'{velodyne_folder}{file_name}_{index}.bin'\n",
    "                        \n",
    "                        img = cv2.imread(source_image)\n",
    "                        dst = cv2.undistort(img, np.array(calib['cam_intrinsic']), distortion, None, cam_intrinsic_n)\n",
    "                        x, y, w, h = roi\n",
    "                        dst = dst[y:y+h, x:x+w]\n",
    "                        cv2.imwrite(destination_image, dst)\n",
    "                        #im = Image.open(source_image)\n",
    "                        #cv2.undistort\n",
    "                        #im.save(destination_image, \"PNG\")\n",
    "                        \n",
    "                        #shutil.copy(source_lidar, destination_lidar) \n",
    "                        \n",
    "                        points = np.fromfile(source_lidar, dtype=np.float32).reshape((-1, 4))\n",
    "                        new_points = np.zeros_like(points)\n",
    "                        new_points[:, 1] = points[:, 0]\n",
    "                        new_points[:, 0] = -points[:, 1]\n",
    "                        new_points[:, 2] = points[:, 2]\n",
    "                        #points[:3, :] = np.dot(kitti_to_once_lidar_inv.rotation_matrix, points[:3, :])  # In KITTI lidar frame.\n",
    "                        with open(destination_lidar, \"w\") as lid_file:\n",
    "                            new_points.tofile(lid_file)                       \n",
    "                \n",
    "                if copy_calib:\n",
    "                    \n",
    "                    kitti_transforms = dict()\n",
    "                    kitti_transforms['P0'] = np.zeros((3, 4))  # Dummy values.\n",
    "                    kitti_transforms['P1'] = np.zeros((3, 4))  # Dummy values.\n",
    "                    kitti_transforms['P2'] = cam_intrinsic # cam_intrinsic @ cam_to_velo #np.hstack((cam_intrinsic, np.zeros((3, 1))))  # Left camera transform.\n",
    "                    kitti_transforms['P3'] = np.zeros((3, 4))  # Dummy values.\n",
    "                    #kitti_transforms['R0_rect'] = r0_rect.rotation_matrix  # Cameras are already rectified.\n",
    "                    kitti_transforms['Tr'] = new_velo_to_cam[:3, :] #np.linalg.inv(cam_to_velo)[:3, :]\n",
    "                    #kitti_transforms['Tr_imu_to_velo'] = imu_to_velo_kitti\n",
    "                    calib_path = os.path.join(sequence_root, 'calib.txt')\n",
    "                    with open(calib_path, \"w\") as calib_file:\n",
    "                        for (key, val) in kitti_transforms.items():\n",
    "                            val = val.flatten()\n",
    "                            val_str = '%.12e' % val[0]\n",
    "                            for v in val[1:]:\n",
    "                                val_str += ' %.12e' % v\n",
    "                            calib_file.write('%s: %s\\n' % (key, val_str))\n",
    "                            \n",
    "                if copy_poses:\n",
    "                    poses = []\n",
    "                    np_poses = []\n",
    "\n",
    "                    with open(f'{once_poses_folder}{sequence}.txt', 'r') as f:\n",
    "                        lines = filter(None, (line.rstrip() for line in f))\n",
    "                        for index, line in enumerate(lines):\n",
    "                            if index >= file_index - num_images and index <= file_index + num_images:\n",
    "                                poses.append(line)\n",
    "                                np_poses.append(np.array([float(x) for x in line.split()]))\n",
    "                    pose_file = '{:0>4}'.format(id)\n",
    "                    with open(f'{poses_folder}{pose_file}.txt', 'w') as f:\n",
    "                        for index, pose in enumerate(np_poses):\n",
    "                            if index == 0:\n",
    "                                f.write('1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0\\n')\n",
    "                            else:\n",
    "                                pose = pose.flatten()\n",
    "                                pose_str = '' #'%.12e' % (1 - (np_poses[0].flatten()[0]) - pose[0])\n",
    "                                #print((np_poses[0].flatten()[0]) - pose[0])\n",
    "                                for i, p in enumerate(pose):\n",
    "                                    if i == 0:\n",
    "                                        pose_str += '%.12e' % (p + (1 - np_poses[0].flatten()[i]))\n",
    "                                    elif i == 5 or i == 10:\n",
    "                                        #print(p + (1 - np_poses[0].flatten()[i]))\n",
    "                                        pose_str += ' %.12e' % (p + (1 - np_poses[0].flatten()[i]))\n",
    "                                    else:\n",
    "                                        #print((np_poses[0].flatten()))\n",
    "                                        pose_str += ' %.12e' % (p + (0 - np_poses[0].flatten()[i]))\n",
    "                                f.write('%s\\n' % (pose_str))\n",
    "                            #f.write('%s\\n' % (pose)) \n",
    "                    with open(f'{sequence_root}poses.txt', 'w') as f:\n",
    "                        for pose in poses:\n",
    "                            f.write('%s\\n' % (pose))\n",
    "                \n",
    "                if copy_timestamps:\n",
    "                    times = []\n",
    "                    for index, frame_index in enumerate(range(file_index - num_images , file_index + num_images + 1)):\n",
    "                        timestamp = frames[frame_index]['frame_id']\n",
    "                        time_diff = float(timestamp) - float(first_timestamp)\n",
    "                        times.append(time_diff / 1000)\n",
    "                                \n",
    "                    times.sort()\n",
    "                    with open(f'{sequence_root}times.txt', 'w') as f:\n",
    "                        for time in times:\n",
    "                            f.write('%s\\n' % (time)) \n",
    "                amount = amount\n",
    "                numbers = numbers + f'{id},'\n",
    "                numbers_vert.append(f'    - {id}')\n",
    "            else:\n",
    "                if os.path.exists(sequence_root):\n",
    "                    os.rmdir(sequence_root)\n",
    "                #print(id)\n",
    "                amount += 1\n",
    "print(amount)\n",
    "print(numbers)\n",
    "for number in numbers_vert:\n",
    "    print(number)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
