{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the detection method, creating Metrics and Points Per Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set paths\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h4>ToDo:</h4>\n",
    "<ol>\n",
    "    <li> Set \"coda_root\" to the root of your <b>CODA directory</b>\n",
    "    <li> Set \"log_finn_root\" to the root of your <b>inference directory</b>.\n",
    "    <li> Set \"print_latex\" to <b>True</b> for a <b>LateX-table</b> output, <b>False</b> for <b>visual</b> output\n",
    "    <li> Set \"plt_show\" to <b>True</b> to show the <b>metrics-plots</b>, <b>False</b> to not show the <b>metrics-plots</b>. (This can slow down the environment, especially over VPN, since the plots add up to a lot of data.)\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coda_root = f'/disk/ml/own_datasets/CODA'\n",
    "log_finn_root = f'/disk/vanishing_data/ju878/log_finn/'\n",
    "\n",
    "print_latex = True\n",
    "plt_show = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = os.path.realpath('../../model_contradictions/')\n",
    "graphics_root = os.path.join(model_root, 'graphics')\n",
    "\n",
    "eval_root = os.path.join(log_finn_root, 'groundtruth_eval')\n",
    "eval_all_root = os.path.join(log_finn_root, 'groundtruth_eval_all')\n",
    "eval_all_anno_root = os.path.join(log_finn_root, 'groundtruth_eval_all_annotation')\n",
    "eval_counts_file = os.path.join(eval_root, 'counts.txt')\n",
    "eval_all_counts_file = os.path.join(eval_all_root, 'counts.txt')\n",
    "eval_all_anno_counts_file = os.path.join(eval_all_anno_root, 'counts.txt')\n",
    "\n",
    "json_cornercases = os.path.join(coda_root, 'corner_case.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for each dataset\n",
    "\n",
    "Corresponding scenario to each position in the \"eval_all_counts\" array\n",
    "\n",
    "    number in array:   0      1     2    3     4    5    6    7     8    9   10  11  12  13  14  15  16  17    18         19           20\n",
    "    scenario:         c_11, c_12, c_13, c_14, c11, c12, c13, c14, c_10, c10, c1, c2, c3, c4, tp, fp, fn, tn, total, original_total, new_label_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads \"counts.txt\" from image based comparison between ground truth and detection method\n",
    "eval_all_counts = np.loadtxt(eval_all_counts_file, delimiter=',')\n",
    "\n",
    "# loads \"counts.txt\" from annotation based comparison between ground truth and detection method\n",
    "eval_all_anno_counts = np.loadtxt(eval_all_anno_counts_file, delimiter=',')\n",
    "\n",
    "eval_once_counts = eval_all_counts[:1034]\n",
    "eval_kitti_counts = eval_all_counts[1034:1341]\n",
    "eval_nuscenes_counts = eval_all_counts[1341:]\n",
    "\n",
    "eval_once_anno_counts = eval_all_anno_counts[:4413]\n",
    "eval_kitti_anno_counts = eval_all_anno_counts[4413:4812]\n",
    "eval_nuscenes_anno_counts = eval_all_anno_counts[4812:]\n",
    "\n",
    "# removes all 0 lines\n",
    "eval_all_anno_counts_cut = eval_all_anno_counts[np.sum(eval_all_anno_counts, axis=1) != 0]\n",
    "eval_once_anno_counts_cut = eval_once_anno_counts[np.sum(eval_once_anno_counts, axis=1) != 0]\n",
    "eval_kitti_anno_counts_cut = eval_kitti_anno_counts[np.sum(eval_kitti_anno_counts, axis=1) != 0]\n",
    "eval_nuscenes_anno_counts_cut = eval_nuscenes_anno_counts[np.sum(eval_nuscenes_anno_counts, axis=1) != 0]\n",
    "\n",
    "eval_all = [eval_all_counts, eval_once_counts, eval_kitti_counts, eval_nuscenes_counts, \n",
    "            eval_all_anno_counts_cut, eval_once_anno_counts_cut, eval_kitti_anno_counts_cut, eval_nuscenes_anno_counts_cut]\n",
    "\n",
    "with open(json_cornercases, 'r') as f:\n",
    "    data_cornercases = json.load(f)\n",
    "    \n",
    "categories = data_cornercases['categories']\n",
    "images = data_cornercases['images']\n",
    "annotations = data_cornercases['annotations']\n",
    "\n",
    "# removes all lines from \"annotations\", which were 0 in the \"eval_***_anno_counts\"\n",
    "annotations_cut = []\n",
    "for annotation in annotations:\n",
    "    if not np.sum(eval_all_anno_counts[annotation['id'] - 1], axis=0) == 0:\n",
    "        annotations_cut.append(annotation)\n",
    "        \n",
    "\n",
    "# Used for Points per Scenario\n",
    "sum_all_counts = np.sum(eval_all_counts, axis=0)\n",
    "sum_once_counts = np.sum(eval_once_counts, axis=0)\n",
    "sum_kitti_counts = np.sum(eval_kitti_counts, axis=0)\n",
    "sum_nuscenes_counts = np.sum(eval_nuscenes_counts, axis=0)\n",
    "\n",
    "sum_all = [sum_all_counts, sum_once_counts, sum_kitti_counts, sum_nuscenes_counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['CODA', 'CODA-ONCE', 'CODA-KITTI', 'CODA-nuScenes', 'CODA-Anno', 'CODA-ONCE-Anno', 'CODA-KITTI-Anno', 'CODA-nuScenes-Anno']\n",
    "categorie_names = ['sc_pedestrian', 'sc_cyclist', 'sc_vehicle', 'sc_animal', 'sc_traffic_facility', 'sc_obstruction', 'sc_misc', \n",
    "                   'c_pedestrian', 'c_cyclist', 'c_car', 'c_truck', 'c_tram', 'c_tricycle', 'c_bus', 'c_bicycle', 'c_moped', 'c_motorcycle',\n",
    "                   'c_stroller', 'c_wheelchair', 'c_cart', 'c_trailer', 'c_construction_vehicle', 'c_recreational_vehicle', 'c_dog', 'c_barrier', \n",
    "                   'c_bollard', 'c_warning_sign', 'c_sentry_box', 'c_traffic_box', 'c_traffic_cone', 'c_traffic_island', 'c_traffic_light', \n",
    "                   'c_traffic_sign', 'c_debris', 'c_suitcace', 'c_dustbin', 'c_concrete_block', 'c_machinery', 'c_chair', 'c_phone_booth', 'c_basket',\n",
    "                   'c_misc']\n",
    "cm_names = ['All', 'Boxes', 'Overlap']\n",
    "cm_anno_names = ['Boxes', 'Overlap']\n",
    "\n",
    "labels = ['tp', 'fp', 'fn', 'tn']\n",
    "title = ['All', 'Boxes', 'Overlap', 'Boxes_anno', 'Overlap_anno']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide data into supercategories and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "supercategories = ['pedestrian', 'cyclist', 'vehicle', 'animal', 'traffic_facility', 'obstruction', 'misc']\n",
    "sc_pedestrian = []\n",
    "sc_cyclist = []\n",
    "sc_vehicle = []\n",
    "sc_animal = []\n",
    "sc_traffic_facility = []\n",
    "sc_obstruction = []\n",
    "sc_misc = []\n",
    "c_pedestrian = []\n",
    "c_cyclist = []\n",
    "c_car = []\n",
    "c_truck = []\n",
    "c_tram = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n",
    "c_tricycle = []\n",
    "c_bus = []\n",
    "c_bicycle = []\n",
    "c_moped = []\n",
    "c_motorcycle = []\n",
    "c_stroller = []\n",
    "c_wheelchair = []\n",
    "c_cart = []\n",
    "c_trailer = []\n",
    "c_construction_vehicle = []\n",
    "c_recreational_vehicle = []\n",
    "c_dog = []\n",
    "c_barrier = []\n",
    "c_bollard = []\n",
    "c_warning_sign = []\n",
    "c_sentry_box = []\n",
    "c_traffic_box = []\n",
    "c_traffic_cone = []\n",
    "c_traffic_island = []\n",
    "c_traffic_light = []\n",
    "c_traffic_sign = []\n",
    "c_debris = []\n",
    "c_suitcace = []\n",
    "c_dustbin = []\n",
    "c_concrete_block = []\n",
    "c_machinery = []\n",
    "c_chair = []\n",
    "c_phone_booth = []\n",
    "c_basket = []\n",
    "c_misc = []\n",
    "\n",
    "for index_anno, annotation in enumerate(annotations_cut):\n",
    "    for categorie in categories:\n",
    "        if annotation['category_id'] == categorie['id']:\n",
    "            categorie_name = categorie['name']\n",
    "            if f'c_{categorie_name}' in globals() and isinstance(globals()[f'c_{categorie_name}'], list):\n",
    "                    globals()[f'c_{categorie_name}'].append(eval_all_anno_counts_cut[index_anno])\n",
    "            for index_sc, sc in enumerate(supercategories):\n",
    "                if categorie['supercategory'] == sc:\n",
    "                    if f'sc_{sc}' in globals() and isinstance(globals()[f'sc_{sc}'], list):\n",
    "                        globals()[f'sc_{sc}'].append(eval_all_anno_counts_cut[index_anno])\n",
    "\n",
    "eval_anomalies = [sc_pedestrian, sc_cyclist, sc_vehicle, sc_animal, sc_traffic_facility, sc_obstruction, sc_misc,\n",
    "                  c_pedestrian, c_cyclist, c_car, c_truck, c_tram, c_tricycle, c_bus, c_bicycle, c_moped, c_motorcycle,\n",
    "                  c_stroller, c_wheelchair, c_cart, c_trailer, c_construction_vehicle, c_recreational_vehicle, c_dog, c_barrier, \n",
    "                  c_bollard, c_warning_sign, c_sentry_box, c_traffic_box, c_traffic_cone, c_traffic_island, c_traffic_light, \n",
    "                  c_traffic_sign, c_debris, c_suitcace, c_dustbin, c_concrete_block, c_machinery, c_chair, c_phone_booth, c_basket,\n",
    "                  c_misc\n",
    "                  ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to create and plot all Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotgraph(counts, dataset, part):\n",
    "    # Create a pie plot\n",
    "    fig = plt.figure(figsize=(6, 4), tight_layout=False)\n",
    "    fig.suptitle(f'{dataset} - {part}')\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.pie(counts[0], labels=labels, autopct='%1.1f%%')\n",
    "    ax.set_title(f'{title[1]}')\n",
    "    \n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.pie(counts[1], labels=labels, autopct='%1.1f%%')\n",
    "    ax.set_title(f'{title[2]}')\n",
    "    \n",
    "    fig.savefig(os.path.join(graphics_root, f'evaluate_detection_method/{dataset}_{part}.svg'), format='svg', dpi=1200)\n",
    "    \n",
    "    # Display the plot\n",
    "    if plt_show:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plotgraph_dataset(counts, counts_anno, dataset, part):\n",
    "    \n",
    "    # Create a pie plot\n",
    "    fig = plt.figure(figsize=(14, 4), tight_layout=False)\n",
    "    fig.suptitle(f'{dataset} - {part}')\n",
    "    ax = fig.add_subplot(151)\n",
    "    ax.pie(counts[0], labels=labels, autopct='%1.1f%%')\n",
    "    ax.set_title(f'{title[0]}')\n",
    "    \n",
    "    ax = fig.add_subplot(152)\n",
    "    ax.pie(counts[1], labels=labels, autopct='%1.1f%%')\n",
    "    ax.set_title(f'{title[1]}')\n",
    "    \n",
    "    ax = fig.add_subplot(153)\n",
    "    ax.pie(counts[2], labels=labels, autopct='%1.1f%%')\n",
    "    ax.set_title(f'{title[2]}')\n",
    "    \n",
    "    ax = fig.add_subplot(154)\n",
    "    ax.pie(counts_anno[0], labels=labels, autopct='%1.1f%%')\n",
    "    ax.set_title(f'{title[3]}')\n",
    "    \n",
    "    ax = fig.add_subplot(155)\n",
    "    ax.pie(counts_anno[1], labels=labels, autopct='%1.1f%%')\n",
    "    ax.set_title(f'{title[4]}')\n",
    "\n",
    "    fig.savefig(os.path.join(graphics_root, f'evaluate_detection_method/{dataset}_{part}.svg'), format='svg', dpi=1200)\n",
    "    # Display the plot\n",
    "    if plt_show:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_iou(cms):\n",
    "    iou = []\n",
    "    for i in range(len(cms[0])):\n",
    "        if (cms[0][i] + cms[1][i] + cms[2][i]) == 0:\n",
    "            iou.append(0)\n",
    "            continue\n",
    "        iou.append((cms[0][i]) / (cms[0][i] + cms[1][i] + cms[2][i]))\n",
    "    return iou\n",
    "\n",
    "def create_aggregated_iou(cm):\n",
    "    if not (cm[0] + cm[1] + cm[2]) == 0:\n",
    "        iou = cm[0] / (cm[0] + cm[1] + cm[2])\n",
    "    else:\n",
    "        iou = 0    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create confusion matrices (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_clustered_cm(eval):\n",
    "    cm_all = [[],[],[],[]]\n",
    "    cm_boxes = [[],[],[],[]]\n",
    "    cm_overlap = [[],[],[],[]]\n",
    "    for e in eval:\n",
    "        if not (e[18]) == 0:\n",
    "            cm_all[0].append(e[14] / e[18])\n",
    "            cm_all[1].append(e[15] / e[18])\n",
    "            cm_all[2].append(e[16] / e[18])\n",
    "            cm_all[3].append(e[17] / e[18])\n",
    "\n",
    "        if not (e[19]) == 0:\n",
    "            cm_boxes[0].append((e[6] + e[7]) / e[19])\n",
    "            cm_boxes[1].append((e[2] + e[3]) / e[19])\n",
    "            cm_boxes[2].append((e[4] + e[5] + e[9]) / e[19])\n",
    "            cm_boxes[3].append((e[0] + e[1] + e[8]) / e[19])\n",
    "\n",
    "        if not (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]) == 0:\n",
    "            cm_overlap[0].append((e[6] + e[7]) / (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]))\n",
    "            cm_overlap[1].append((e[2] + e[3]) / (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]))\n",
    "            cm_overlap[2].append((e[4] + e[5]) / (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]))\n",
    "            cm_overlap[3].append((e[0] + e[1]) / (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]))\n",
    "    \n",
    "    return cm_all, cm_boxes, cm_overlap\n",
    "\n",
    "def create_individual_cm(eval):\n",
    "    cm_all = [[],[],[],[]]\n",
    "    cm_boxes = [[],[],[],[]]\n",
    "    cm_overlap = [[],[],[],[]]\n",
    "    for e in eval:\n",
    "        if not (e[18]) == 0:\n",
    "            cm_all[0].append((e[2] + e[3] + e[6] + e[7]) / e[18])\n",
    "            cm_all[1].append((e[12] + e[13]) / e[18])\n",
    "            cm_all[2].append((e[0] + e[1] + e[4] + e[5] + e[8] + e[9]) / e[18])\n",
    "            cm_all[3].append((e[10] + e[11]) / e[18])\n",
    "\n",
    "        if not (e[19]) == 0:\n",
    "            cm_boxes[0].append((e[2] + e[3] + e[6] + e[7]) / e[19])\n",
    "            cm_boxes[1].append(0 / e[19])\n",
    "            cm_boxes[2].append((e[0] + e[1] + e[4] + e[5] + e[8] + e[9]) / e[19])\n",
    "            cm_boxes[3].append(0 / e[19])\n",
    "\n",
    "        if not (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]) == 0:\n",
    "            cm_overlap[0].append((e[2] + e[3] + e[6] + e[7]) / (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]))\n",
    "            cm_overlap[1].append(0 / (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]))\n",
    "            cm_overlap[2].append((e[0] + e[1] + e[4] + e[5] + e[8] + e[9]) / (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]))\n",
    "            cm_overlap[3].append(0 / (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]))\n",
    "    \n",
    "    return cm_all, cm_boxes, cm_overlap\n",
    "\n",
    "def create_aggregated_clustered_cm(eval):\n",
    "    e = np.sum(eval, axis=0)\n",
    "    cm_all = [e[14], e[15], e[16], e[17]]\n",
    "    cm_boxes = [e[6] + e[7], e[2] + e[3], e[4] + e[5] + e[9], e[0] + e[1] + e[8]]\n",
    "    cm_overlap = [e[6] + e[7], e[2] + e[3], e[4] + e[5], e[0] + e[1]]\n",
    "    \n",
    "        \n",
    "    if not (e[18]) == 0:\n",
    "        cm_all = cm_all / e[18]\n",
    "    if not (e[19]) == 0:\n",
    "        cm_boxes = cm_boxes / e[19]\n",
    "    if not (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]) == 0:\n",
    "        cm_overlap = cm_overlap / (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7])\n",
    "    \n",
    "    return cm_all, cm_boxes, cm_overlap\n",
    "\n",
    "def create_aggregated_cm(eval):\n",
    "    e = np.sum(eval, axis=0)\n",
    "    cm_all = [(e[2] + e[3] + e[6] + e[7]), (e[12] + e[13]), (e[0] + e[1] + e[4] + e[5] + e[8] + e[9]), (e[10] + e[11])]\n",
    "    cm_boxes = [(e[2] + e[3] + e[6] + e[7]), 0, (e[0] + e[1] + e[4] + e[5] + e[8] + e[9]), 0]\n",
    "    cm_overlap = [(e[2] + e[3] + e[6] + e[7]), 0, (e[0] + e[1] + e[4] + e[5] + e[8] + e[9]), 0]\n",
    "    \n",
    "        \n",
    "    if not (e[18]) == 0:\n",
    "        cm_all = cm_all / e[18]\n",
    "    if not (e[19]) == 0:\n",
    "        cm_boxes = cm_boxes / e[19]\n",
    "    if not (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7]) == 0:\n",
    "        cm_overlap = cm_overlap / (e[0] + e[1] + e[2] + e[3] + e[4] + e[5] + e[6] + e[7])\n",
    "    \n",
    "    return cm_all, cm_boxes, cm_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate all Metrics (individual and aggregated)\n",
    "\n",
    "If \"index\" > 4 (eval_all) only boxes and overlap are calculated, since anomaly based data has only boxes and overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual(index, e, clustered):\n",
    "    individual_count = []\n",
    "    individual_iou = []\n",
    "    individual_ap = []\n",
    "    individual_ar = []\n",
    "    individual_f1 = []\n",
    "    individual_cm = []\n",
    "    if clustered:\n",
    "        confusion_matrices = create_individual_clustered_cm(e)\n",
    "    else:\n",
    "        confusion_matrices = create_individual_cm(e)\n",
    "    for i, cms in enumerate(confusion_matrices):\n",
    "        \n",
    "        if index >= 4 and i == 0:\n",
    "            continue\n",
    "        \n",
    "        # create iou\n",
    "        m_iou = create_individual_iou(cms)\n",
    "        if not len(m_iou) == 0:\n",
    "            iou = sum(m_iou) / len(m_iou)\n",
    "        else:\n",
    "            iou = 0\n",
    "        \n",
    "        # create ap and ar\n",
    "        precision = 0\n",
    "        counter_precision = 0\n",
    "        recall = 0\n",
    "        counter_recall = 0\n",
    "        for cm in range(len(cms[0])):\n",
    "            counter_precision += 1\n",
    "            counter_recall += 1\n",
    "            if (cms[0][cm] + cms[1][cm]) == 0:\n",
    "                continue\n",
    "            precision += (cms[0][cm]) / (cms[0][cm] + cms[1][cm])\n",
    "            if (cms[0][cm] + cms[2][cm]) == 0:\n",
    "                continue\n",
    "            recall += (cms[0][cm]) / (cms[0][cm] + cms[2][cm])\n",
    "            \n",
    "        if not counter_precision == 0:\n",
    "            precision = (precision / counter_precision)\n",
    "        if not counter_recall == 0:\n",
    "            recall = (recall / counter_recall)\n",
    "        \n",
    "        # create f1\n",
    "        if not (precision + recall) == 0:\n",
    "            f1 = (2 * (precision * recall)) / (precision + recall)\n",
    "        else:\n",
    "            f1 = 0\n",
    "        \n",
    "        individual_count.append(counter_precision)\n",
    "        individual_iou.append(iou)  \n",
    "        individual_ap.append(precision)\n",
    "        individual_ar.append(recall)\n",
    "        individual_f1.append(f1)\n",
    "        conf_mat = [0, 0, 0, 0]\n",
    "        for cm in range(len(cms[0])):\n",
    "            conf_mat[0] += cms[0][cm]\n",
    "            conf_mat[1] += cms[1][cm]\n",
    "            conf_mat[2] += cms[2][cm]\n",
    "            conf_mat[3] += cms[3][cm]\n",
    "        for c in range(len(conf_mat)):\n",
    "            if not len(cms[0]) == 0:\n",
    "                conf_mat[c] = conf_mat[c] / len(cms[0])\n",
    "        individual_cm.append(conf_mat)\n",
    "    \n",
    "    return individual_iou, individual_ap, individual_ar, individual_f1, individual_cm, individual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregated(index, e, clustered):\n",
    "    aggregated_iou = []\n",
    "    aggregated_ap = []\n",
    "    aggregated_ar = []\n",
    "    aggregated_f1 = []\n",
    "    if clustered:\n",
    "        confusion_matrices = create_aggregated_clustered_cm(e)\n",
    "    else:\n",
    "        confusion_matrices = create_aggregated_cm(e)\n",
    "    for i, cms in enumerate(confusion_matrices):\n",
    "        \n",
    "        if index >= 4 and i == 0:\n",
    "            continue\n",
    "        # create iou\n",
    "        iou = create_aggregated_iou(cms)\n",
    "        \n",
    "        # create ap and ar\n",
    "        if not (cms[0] + cms[1]) == 0:\n",
    "            precision = (cms[0]) / (cms[0] + cms[1])\n",
    "        else:\n",
    "            precision = 0\n",
    "        if not (cms[0] + cms[2]) == 0:\n",
    "            recall = (cms[0]) / (cms[0] + cms[2])\n",
    "        else:\n",
    "            recall = 0\n",
    "        \n",
    "        # create f1\n",
    "        if not (precision + recall) == 0:\n",
    "            f1 = (2 * (precision * recall)) / (precision + recall)\n",
    "        else:\n",
    "            f1 = 0\n",
    "             \n",
    "        aggregated_iou.append(iou)  \n",
    "        aggregated_ap.append(precision)\n",
    "        aggregated_ar.append(recall) \n",
    "        aggregated_f1.append(f1)\n",
    "    \n",
    "    if index >= 4:\n",
    "        confusion_matrices = confusion_matrices[1:]\n",
    "    return aggregated_iou, aggregated_ap, aggregated_ar, aggregated_f1, confusion_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_for_visual(index, i, individual_cl, aggregated_cl, individual, aggregated):\n",
    "    \n",
    "    print(f'Count: ' + str(individual[5][i]) + '\\n')\n",
    "                \n",
    "    print('Clustered')\n",
    "    print('individual IoU: ' + str(round(individual_cl[0][i] * 100, 1)))\n",
    "    print('individual AP: ' + str(round(individual_cl[1][i] * 100, 1)))\n",
    "    print('individual AR: ' + str(round(individual_cl[2][i] * 100, 1)))\n",
    "    print('individual F1: ' + str(round(individual_cl[3][i] * 100, 1)))\n",
    "    \n",
    "    print('aggregated IoU: ' + str(round(aggregated_cl[0][i] * 100, 1)))\n",
    "    print('aggregated AP: ' + str(round(aggregated_cl[1][i] * 100, 1)))\n",
    "    print('aggregated AR: ' + str(round(aggregated_cl[2][i] * 100, 1)))\n",
    "    print('aggregated F1: ' + str(round(aggregated_cl[3][i] * 100, 1)) + '\\n')\n",
    "    \n",
    "    print('Not clustered')\n",
    "    print('individual IoU: ' + str(round(individual[0][i] * 100, 1)))\n",
    "    print('individual AP: ' + str(round(individual[1][i] * 100, 1)))\n",
    "    print('individual AR: ' + str(round(individual[2][i] * 100, 1)))\n",
    "    print('individual F1: ' + str(round(individual[3][i] * 100, 1)))\n",
    "    \n",
    "    print('aggregated IoU: ' + str(round(aggregated[0][i] * 100, 1)))\n",
    "    print('aggregated AP: ' + str(round(aggregated[1][i] * 100, 1)))\n",
    "    print('aggregated AR: ' + str(round(aggregated[2][i] * 100, 1)))\n",
    "    print('aggregated F1: ' + str(round(aggregated[3][i] * 100, 1)) + '\\n' + '\\n')\n",
    "    \n",
    "def print_for_latex(i, name, individual_cl, aggregated_cl, individual, aggregated):\n",
    "    print('& ' + name + ' & ' +\n",
    "        str(individual[5][i]) + ' & ' +\n",
    "        str(round(individual_cl[0][i] * 100, 1)) + ' & ' + \n",
    "        str(round(individual_cl[1][i] * 100, 1)) + ' & ' + \n",
    "        str(round(individual_cl[2][i] * 100, 1)) + ' & ' + \n",
    "        str(round(individual_cl[3][i] * 100, 1)) + ' & ' + \n",
    "        str(round(aggregated_cl[0][i] * 100, 1)) + ' & ' + \n",
    "        str(round(aggregated_cl[1][i] * 100, 1)) + ' & ' + \n",
    "        str(round(aggregated_cl[2][i] * 100, 1)) + ' & ' + \n",
    "        str(round(aggregated_cl[3][i] * 100, 1)) + ' & ' + \n",
    "        str(round(individual[0][i] * 100, 1)) + ' & ' + \n",
    "        str(round(individual[1][i] * 100, 1)) + ' & ' + \n",
    "        str(round(individual[2][i] * 100, 1)) + ' & ' + \n",
    "        str(round(individual[3][i] * 100, 1)) + ' & ' + \n",
    "        str(round(aggregated[0][i] * 100, 1)) + ' & ' + \n",
    "        str(round(aggregated[1][i] * 100, 1)) + ' & ' + \n",
    "        str(round(aggregated[2][i] * 100, 1)) + ' & ' + \n",
    "        str(round(aggregated[3][i] * 100, 1)) + ' \\\\\\\\'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main functions to combine all above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IoU_AP_AR_F1_datasets(eval_all):\n",
    "    all_individual = []\n",
    "    all_aggregated = []\n",
    "    for index, e in enumerate(eval_all):\n",
    "        # create metrics for individual and aggregated metrics for each clustered and un-clustered ground truth\n",
    "        individual_cl = get_individual(index, e, True)\n",
    "        individual = get_individual(index, e, False)\n",
    "        aggregated_cl = get_aggregated(index, e, True)\n",
    "        aggregated = get_aggregated(index, e, False)\n",
    "        \n",
    "        # print outputs\n",
    "        for i in range(len(individual[4])):\n",
    "            print(f'{dataset_names[index]}: {cm_names[i]}')\n",
    "            if print_latex:\n",
    "                print_for_latex(i, dataset_names[index], individual_cl, aggregated_cl, individual, aggregated)\n",
    "            else:\n",
    "                print_for_visual(index, i, individual_cl, aggregated_cl, individual, aggregated)\n",
    "        \n",
    "        all_individual.append(individual[4])\n",
    "        all_aggregated.append(aggregated[4])\n",
    "    \n",
    "    # create plots\n",
    "    for index in range(4):\n",
    "        plotgraph_dataset(all_individual[index], all_individual[index + 4], dataset_names[index], 'Individual')\n",
    "        plotgraph_dataset(all_aggregated[index], all_aggregated[index + 4], dataset_names[index], 'Aggregated')\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IoU_AP_AR_F1_anomalies(eval_all):\n",
    "    for index, e in enumerate(eval_all):\n",
    "        # create metrics for individual and aggregated metrics for each clustered and un-clustered ground truth\n",
    "        # the \"index\" for \"get_individual\" is set to 4 since all anomaly based data has only boxes and overlap\n",
    "        individual_cl = get_individual(4, e, True)\n",
    "        individual = get_individual(4, e, False)\n",
    "        aggregated_cl = get_aggregated(4, e, True)\n",
    "        aggregated = get_aggregated(4, e, False)\n",
    "        \n",
    "        # print outputs\n",
    "        for i in range(len(individual[4])):\n",
    "            print(f'{categorie_names[index]}: {cm_anno_names[i]}')\n",
    "            if print_latex:\n",
    "                print_for_latex(i, categorie_names[index].split('_')[1], individual_cl, aggregated_cl, individual, aggregated)\n",
    "            else:\n",
    "                print_for_visual(index, i, individual_cl, aggregated_cl, individual, aggregated)\n",
    "        \n",
    "        # create plots       \n",
    "        plotgraph(individual[4], categorie_names[index], 'Individual')\n",
    "        plotgraph(aggregated[4], categorie_names[index], 'Aggregated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_IoU_AP_AR_F1_datasets(eval_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_IoU_AP_AR_F1_anomalies(eval_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Points per scenario as defined by Sartoris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addlabels(x,y):\n",
    "    for i in range(len(x)):\n",
    "        if y[i] == 0:\n",
    "            plt.text(i,y[i]+1.5,int(y[i]), ha = 'center')\n",
    "            continue\n",
    "        plt.text(i,y[i]*1.005,int(y[i]), ha = 'center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['CODA', 'CODA-ONCE', 'CODA-KITTI', 'CODA-nuScenes']\n",
    "scenario_labels = ['1', '2', '3', '4']\n",
    "for index, s in enumerate(sum_all):\n",
    "    scenario1 = s[0] + s[4] + s[10]\n",
    "    scenario2 = s[1] + s[5] + s[11]\n",
    "    scenario3 = s[2] + s[6] + s[12]\n",
    "    scenario4 = s[3] + s[7] + s[13] \n",
    "    scenarios = [scenario1, scenario2, scenario3, scenario4]\n",
    "    \n",
    "    plt.bar(scenario_labels, scenarios, color=[(0.13,0.54,0.13), (0.25,0.41,0.7), (0.65,0.13,0.13), (0.9,0.9,0)])\n",
    "    addlabels(scenario_labels, scenarios)\n",
    "    plt.xlabel('Scenario')\n",
    "    plt.ylabel('Number of Points')\n",
    "    plt.yscale('log')\n",
    "    plt.title(f'{names[index]}')\n",
    "    \n",
    "    plt.savefig(os.path.join(graphics_root, f'points_per_scenario_{names[index]}.svg'), format='svg', dpi=1200)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
